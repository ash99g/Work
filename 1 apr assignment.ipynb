{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b24c3b-a996-47ca-a38b-4288c9c0b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Explain the difference between linear regression and logistic regression models. Provide an example of\n",
    "#     a scenario where logistic regression would be more appropriate.\n",
    "# Ans. Linear Regression is used to handle regression problems whereas Logistic regression is used to handle the classification problems.             \n",
    "#      Linear regression provides a continuous output but Logistic regression provides discreet output.\n",
    "#      Linear regression is a data analysis technique that predicts the value of unknown data by using another related and known data value.\n",
    "\n",
    "#      It mathematically models the unknown or dependent variable and the known or independent variable as a linear equation.\n",
    "#      Logistic regression is a data analysis technique that uses mathematics to find the relationships between two data factors. It then uses    \n",
    "#      this relationship to predict the value of one of those factors based on the other\n",
    "\n",
    "#      Example-Credit scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba77a4-4ea4-4009-b275-fdf1ef012286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What is the cost function used in logistic regression, and how is it optimized?\n",
    "# Ans.The cost function used in Logistic Regression is Log Loss.Logarithmic loss indicates how close a prediction probability comes to the          \n",
    "#     actual/corresponding true value. As a result, it turns out that maximizing the likelihood is equivalent to minimizing the mean square error    \n",
    "#     (MSE), i.e. this error function is widely used in regression problems for a reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ae030-5627-416e-91cf-b32e74b97007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting.\n",
    "# Ans.Regularization is a way of finding a good bias-variance tradeoff by tuning the complexity of the model. It is a very useful method to         \n",
    "#     handle collinearity (high correlation among features), filter out noise from data, and eventually prevent overfitting.\n",
    "\n",
    "#     That's the set of parameters. In short, Regularization in machine learning is the process of regularizing the parameters that constrain,  \n",
    "#     regularizes, or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, avoiding the risk of Overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37fcb3e-6dc2-4751-bcf1-3c3dc115891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression model?\n",
    "# Ans.An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification       \n",
    "#     thresholds. This curve plots two parameters: True Positive Rate. False Positive Rate.\n",
    "\n",
    "#    ROC curves in logistic regression are used for determining the best cutoff value for predicting whether a new observation is a \"failure\" (0) or a \"success\" (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58464a-e418-41a8-814d-ab2d5c5b436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. What are some common techniques for feature selection in logistic regression? How do these techniques help improve the model's performance?\n",
    "# Ans.1.Extra Tree Classifier.\n",
    "#    2.Pearson correlation.\n",
    "#    3.Forward selection.\n",
    "#    4.Chi-square.\n",
    "#    5.Logit (Logistic Regression model)    \n",
    "    \n",
    "#    Feature Selection is the method of reducing the input variable to your model by using only relevant data and getting rid of noise in data.   \n",
    "#    It is the process of automatically choosing relevant features for your machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0277e2-721c-402d-ab35-45ad8a8c575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing with class imbalance?\n",
    "# Ans.In logistic regression, another technique comes handy to work with imbalance distribution. This is to use class-weights in accordance with    \n",
    "#     the class distribution. Class-weights is the extent to which the algorithm is punished for any wrong prediction of that class.\n",
    "\n",
    "#    1.Sample Dataset\n",
    "#    2.Random Under-Sampling. \n",
    "#    3.Random Over-Sampling.\n",
    "#    4.Random Under-Sampling With Imblearn. \n",
    "#    5.Random Over-Sampling With imblearn.\n",
    "#    6.Under-Sampling: Tomek Links.\n",
    "#    7.Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0dfb9e-0fe8-4b4e-a471-3c0acc154881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Can you discuss some common issues and challenges that may arise when implementing logisticregression, and how they can be addressed? \n",
    "#     For example, what can be done if there is multicollinearity among the independent variables?\n",
    "# Ans.1.If the number of observations is lesser than the number of features, Logistic Regression should not be used, otherwise, it may lead to overfitting.\n",
    "#     2.It constructs linear boundaries.\n",
    "#\t  3.The major limitation of Logistic Regression is the assumption of linearity between the dependent variable and the independent variables.\n",
    "#     4.It can only be used to predict discrete functions. Hence, the dependent variable of Logistic Regression is bound to the discrete number set.\n",
    "    \n",
    "#     Logistic regression can also be prone to overfitting, particularly when there is a high number of predictor variables within the model.         \n",
    "#     Regularization is typically used to penalize parameters large coefficients when the model suffers from high dimensionality.\n",
    "    \n",
    "#     To reduce the amount of multicollinearity found in a statistical model, one can remove the specific variables identified as the most        \n",
    "#     collinear. You can also try to combine or transform the offending variables to lower their correlation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
